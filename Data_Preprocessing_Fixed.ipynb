{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1e92983",
   "metadata": {},
   "source": [
    "# Data Preprocessing Notebook\n",
    "\n",
    "This notebook handles WAV/MIDI processing and DataFrame creation.\n",
    "The output `music_df.pkl` will be used in the training notebook."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**This code imports essential libraries and modules needed for data preprocessing, including libraries for handling audio (e.g., `librosa`), MIDI processing (`pretty_midi`), data manipulation (`pandas`, `numpy`), machine learning utilities (`sklearn`), and PyTorch for deep learning. It also imports utilities for multithreading and operating system interactions.**",
   "id": "ee69ed190219dff1"
  },
  {
   "cell_type": "code",
   "id": "50b03ca3a48e176e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T11:48:50.185130Z",
     "start_time": "2025-04-30T11:48:19.717790Z"
    }
   },
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from fractions import Fraction\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import tables\n",
    "import pretty_midi\n",
    "import psutil\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# from tqdm.notebook import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**This code checks the PyTorch version, determines whether CUDA (GPU acceleration) is available, and prints the CUDA device name if detected. If CUDA is not available, it prints a message indicating that.**",
   "id": "17d919a768237e48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"CUDA not detected!\")"
   ],
   "id": "b6841b0ef22e5b2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eed542621091c1c1",
   "metadata": {},
   "source": [
    "# Define the target subdirectory\n",
    "subdirectory = Path(\"maestro-v3.0.0\")\n",
    "\n",
    "# Dictionary to hold files grouped by their base name\n",
    "file_dict = defaultdict(dict)\n",
    "\n",
    "# Traverse directory and collect files\n",
    "for file in subdirectory.rglob('*'):\n",
    "    if file.is_file():\n",
    "        base_name = file.stem  # Filename without extension\n",
    "        ext = file.suffix  # File extension (including dot, e.g., \".txt\")\n",
    "        file_dict[base_name][ext] = str(file)\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "\n",
    "# Remove empty entries before making DataFrame\n",
    "file_dict = {k: v for k, v in file_dict.items() if v}  # Keep only non-empty dicts\n",
    "music_df = pd.DataFrame.from_dict(file_dict, orient='index')\n",
    "\n",
    "# Display the DataFrame\n",
    "music_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c18f892eb8711fd0",
   "metadata": {},
   "source": [
    "# Add columns for spectrogram and MIDI token sequence\n",
    "# Add columns for extracted notes with timestamps\n",
    "music_df[\"WAV_Notes\"] = None\n",
    "music_df[\"WAV_Timestamps\"] = None\n",
    "music_df[\"MIDI_Notes\"] = None\n",
    "music_df[\"MIDI_Timestamps\"] = None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "35f7ed55988724e5",
   "metadata": {},
   "source": [
    "# Create a function to extract notes and timestamps from a WAV file\n",
    "def extract_notes_from_wav(wav_path):\n",
    "    \"\"\"\n",
    "    Extract active MIDI notes and their corresponding timestamps from a WAV file.\n",
    "\n",
    "    This function processes an audio file to compute its Constant-Q Transform (CQT) and identifies\n",
    "    the active notes based on their power in decibel scale. The active notes are converted to\n",
    "    MIDI note numbers and their timestamps are calculated.\n",
    "\n",
    "    Args:\n",
    "        wav_path (str): Path to the WAV file to be processed.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - active_notes (np.ndarray): Array of active MIDI note numbers.\n",
    "            - timestamps (np.ndarray): Array of corresponding timestamps for the active notes.\n",
    "\n",
    "    Notes:\n",
    "        - The CQT is computed with frequencies corresponding to piano notes, starting from C1.\n",
    "        - Notes are considered active if their power exceeds -20 dB.\n",
    "\n",
    "    Example:\n",
    "        >>> notes, times = extract_notes_from_wav(\"example.wav\")\n",
    "        >>> print(\"Notes:\", notes)\n",
    "        >>> print(\"Timestamps:\", times)\n",
    "    \"\"\"\n",
    "    # Load the audio file using Librosa\n",
    "    # y: Audio time series data\n",
    "    # sr: Sampling rate of the audio file\n",
    "    y, sr = librosa.load(wav_path, sr=None)\n",
    "\n",
    "    # Compute the Constant-Q Transform (CQT) of the audio signal\n",
    "    # This provides a time-frequency representation\n",
    "    cqt = np.abs(librosa.cqt(y, sr=sr))  # Take the magnitude of the CQT\n",
    "    cqt_db = librosa.amplitude_to_db(cqt, ref=np.max)  # Convert to decibel scale\n",
    "\n",
    "    # Define the minimum frequency (fmin) for the CQT frequency bins\n",
    "    # Using C1 (the lowest note on the piano, approximately 32.7 Hz) as the starting frequency\n",
    "    fmin = librosa.note_to_hz(\"C1\")\n",
    "\n",
    "    # Compute the frequencies corresponding to the CQT bins\n",
    "    frequencies = librosa.cqt_frequencies(n_bins=cqt.shape[0], fmin=fmin)\n",
    "\n",
    "    # Convert frame indices to time values\n",
    "    times = librosa.frames_to_time(np.arange(cqt.shape[1]), sr=sr)\n",
    "\n",
    "    # Convert the CQT frequencies to MIDI note numbers\n",
    "    midi_numbers = librosa.hz_to_midi(frequencies)\n",
    "\n",
    "    # Identify active notes based on a threshold in the decibel scale\n",
    "    # Notes are considered active if their power exceeds -20 dB at any time\n",
    "    active_notes = midi_numbers[(cqt_db > -20).any(axis=1)]\n",
    "    timestamps = times[(cqt_db > -20).any(axis=0)]\n",
    "\n",
    "    # Return the active MIDI notes and their corresponding timestamps\n",
    "    return active_notes, timestamps"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_notes_from_midi(midi_path):\n",
    "    \"\"\"\n",
    "    Extract MIDI notes and their corresponding timestamps from a given MIDI file.\n",
    "\n",
    "    This function processes a MIDI file to retrieve the pitch (MIDI note numbers)\n",
    "    and start times (timestamps) for each note. Notes and timestamps are returned\n",
    "    as separate arrays.\n",
    "\n",
    "    Args:\n",
    "        midi_path (str): Path to the MIDI file to be processed.\n",
    "\n",
    "    Returns:\n",
    "        Tuple:\n",
    "            - list: A list of unique MIDI note numbers (pitches).\n",
    "            - list: A list of timestamps indicating the start times of the notes.\n",
    "\n",
    "    Notes:\n",
    "        - If the MIDI file cannot be parsed, the function returns (None, None).\n",
    "        - Duplicate notes are removed from the returned list of notes.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the MIDI file using pretty_midi\n",
    "        midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
    "\n",
    "        notes = []  # List to store note pitches\n",
    "        timestamps = []  # List to store timestamp of each note\n",
    "\n",
    "        # Iterate over all instruments and their notes to extract data\n",
    "        for instrument in midi_data.instruments:\n",
    "            for note in instrument.notes:\n",
    "                notes.append(note.pitch)  # Append note pitch (as MIDI number)\n",
    "                timestamps.append(note.start)  # Append note-on timestamp\n",
    "\n",
    "        # Return unique notes and their corresponding timestamps\n",
    "        return list(set(notes)), timestamps\n",
    "    except:\n",
    "        # In case of any error, return None for both notes and timestamps\n",
    "        return None, None"
   ],
   "id": "4693e205",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define a function to process a single row\n",
    "def process_row(index, row):\n",
    "    result = {\"index\": index, \"WAV_Notes\": None, \"WAV_Timestamps\": None, \"MIDI_Notes\": None, \"MIDI_Timestamps\": None}\n",
    "\n",
    "    # Process WAV files if they exist\n",
    "    if '.wav' in row:\n",
    "        notes, timestamps = extract_notes_from_wav(row['.wav'])\n",
    "        result[\"WAV_Notes\"] = notes\n",
    "        result[\"WAV_Timestamps\"] = timestamps\n",
    "\n",
    "    # Process MIDI files if they exist\n",
    "    if '.mid' in row or '.midi' in row:\n",
    "        midi_file = row.get('.mid') or row.get('.midi')\n",
    "        notes, timestamps = extract_notes_from_midi(midi_file)\n",
    "        result[\"MIDI_Notes\"] = notes\n",
    "        result[\"MIDI_Timestamps\"] = timestamps\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Use ThreadPoolExecutor to process rows in parallel\n",
    "with ThreadPoolExecutor(max_workers=12) as executor:\n",
    "    futures = [executor.submit(process_row, index, row) for index, row in music_df.iterrows()]\n",
    "    for future in futures:\n",
    "        row_result = future.result()\n",
    "        # Update the DataFrame with results\n",
    "        music_df.at[row_result[\"index\"], \"WAV_Notes\"] = row_result[\"WAV_Notes\"]\n",
    "        music_df.at[row_result[\"index\"], \"WAV_Timestamps\"] = row_result[\"WAV_Timestamps\"]\n",
    "        music_df.at[row_result[\"index\"], \"MIDI_Notes\"] = row_result[\"MIDI_Notes\"]\n",
    "        music_df.at[row_result[\"index\"], \"MIDI_Timestamps\"] = row_result[\"MIDI_Timestamps\"]"
   ],
   "id": "900c2ff8fd83a707",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c3d16ce95708a2a6",
   "metadata": {},
   "source": [
    "# Save using Pickle (Python-specific)\n",
    "music_df.to_pickle(\"music_data.pkl\")\n",
    "\n",
    "# Save using HDF5 (requires the PyTables library)\n",
    "# music_df.to_hdf(\"music_data.h5\", key=\"df\", mode=\"w\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "60888b800ff9509a",
   "metadata": {},
   "source": "# music_df = pd.read_pickle(\"music_data.pkl\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "music_df[\"WAV_Notes_Clean\"] = music_df[\"WAV_Notes\"].apply(\n",
    "    lambda notes: [int(round(n)) for n in notes] if isinstance(notes, (list, np.ndarray)) else None\n",
    ")"
   ],
   "id": "24aeeafecce406dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rationalize_timestamps(timestamps, resolution=480, tempo=120):\n",
    "    \"\"\"\n",
    "    Snap timestamps to nearest MIDI tick based on desired resolution and tempo.\n",
    "\n",
    "    Args:\n",
    "        timestamps (list or np.ndarray): List of float timestamps (seconds).\n",
    "        resolution (int): MIDI ticks per quarter note (default 480).\n",
    "        tempo (float): BPM for conversion (default 120 BPM).\n",
    "\n",
    "    Returns:\n",
    "        list[int]: Snapped ticks.\n",
    "    \"\"\"\n",
    "    if not isinstance(timestamps, (list, np.ndarray)):\n",
    "        return None\n",
    "    ticks_per_second = (resolution * tempo) / 60.0\n",
    "    return [round(t * ticks_per_second) for t in timestamps]"
   ],
   "id": "df34c46355c8ebdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "music_df[\"WAV_Timestamps_Snapped\"] = music_df[\"WAV_Timestamps\"].apply(rationalize_timestamps)\n",
    "music_df[\"MIDI_Timestamps_Snapped\"] = music_df[\"MIDI_Timestamps\"].apply(rationalize_timestamps)"
   ],
   "id": "6b8628a184d771bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "music_df[\"WAV_Timestamp_Real+Tick\"] = music_df.apply(\n",
    "    lambda row: list(zip(\n",
    "        row[\"WAV_Timestamps\"],\n",
    "        rationalize_timestamps(row[\"WAV_Timestamps\"])\n",
    "    )) if isinstance(row[\"WAV_Timestamps\"], (list, np.ndarray)) else None,\n",
    "    axis=1\n",
    ")\n"
   ],
   "id": "e1ce9e53f81dd179",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9da7c6117698de01",
   "metadata": {},
   "source": [
    "def midi_to_token_sequence(midi_path):\n",
    "    \"\"\"\n",
    "    Converts a MIDI file into a sequence of tokenized note values with additional features.\n",
    "\n",
    "    Args:\n",
    "        midi_path (str): Path to the MIDI file.\n",
    "\n",
    "    Returns:\n",
    "        list: List of tokenized MIDI events [(pitch, velocity, duration, time_since_last_note)].\n",
    "    \"\"\"\n",
    "    try:\n",
    "        midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
    "        tokens = []\n",
    "\n",
    "        for instrument in midi_data.instruments:\n",
    "            previous_time = 0  # Track time of last note\n",
    "            for note in instrument.notes:\n",
    "                pitch = note.pitch  # MIDI note number (0-127)\n",
    "                velocity = note.velocity  # How hard the note was pressed (0-127)\n",
    "                duration = note.end - note.start  # Note duration in seconds\n",
    "                time_since_last_note = note.start - previous_time  # Time since last note\n",
    "                previous_time = note.start  # Update last note time\n",
    "\n",
    "                tokens.append((pitch, velocity, duration, time_since_last_note))\n",
    "\n",
    "        return tokens if tokens else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {midi_path}: {e}\")\n",
    "        return None\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aef719642d7d8668",
   "metadata": {},
   "source": [
    "class MIDIVocabulary:\n",
    "    def __init__(self,\n",
    "                 pitch_classes=128,\n",
    "                 velocity_bins=32,\n",
    "                 duration_bins=64,\n",
    "                 time_bins=64,\n",
    "                 max_velocity=127,\n",
    "                 max_duration=4.0,  # in seconds\n",
    "                 max_time_gap=4.0):\n",
    "        self.pitch_classes = pitch_classes\n",
    "        self.velocity_bins = velocity_bins\n",
    "        self.duration_bins = duration_bins\n",
    "        self.time_bins = time_bins\n",
    "        self.max_velocity = max_velocity\n",
    "        self.max_duration = max_duration\n",
    "        self.max_time_gap = max_time_gap\n",
    "\n",
    "    def _quantize(self, value, bins, max_val):\n",
    "        if value is None or not np.isfinite(value):\n",
    "            return 0  # fallback/default bin\n",
    "        bin_index = int((value / max_val) * bins)\n",
    "        return max(0, min(bins - 1, bin_index))\n",
    "\n",
    "    def encode(self, midi_tokens):\n",
    "        \"\"\"\n",
    "        Converts raw tokens into bin indices: (pitch, velocity_bin, duration_bin, time_bin)\n",
    "        \"\"\"\n",
    "        encoded_tokens = []\n",
    "        for token in midi_tokens:\n",
    "            if not isinstance(token, (tuple, list)) or len(token) < 4:\n",
    "                raise ValueError(f\"Malformed MIDI token: {token}\")\n",
    "            pitch, velocity, duration, time_gap = token\n",
    "            pitch = int(pitch)\n",
    "            velocity_bin = self._quantize(velocity, self.velocity_bins, self.max_velocity)\n",
    "            duration_bin = self._quantize(duration, self.duration_bins, self.max_duration)\n",
    "            time_bin = self._quantize(time_gap, self.time_bins, self.max_time_gap)\n",
    "            encoded_tokens.append((pitch, velocity_bin, duration_bin, time_bin))\n",
    "        return encoded_tokens"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "28a61e8e2af81a35",
   "metadata": {},
   "source": [
    "# Ensure the necessary columns exist and explicitly set dtype to 'object'\n",
    "for col in [\"MIDI_Tokens\", \"Encoded_MIDI_Tokens\"]:\n",
    "    if col not in music_df.columns:\n",
    "        music_df[col] = None\n",
    "    else:\n",
    "        music_df[col] = music_df[col].astype(\"object\")  # Ensure proper type\n",
    "\n",
    "midi_vocab = MIDIVocabulary()  # Create an instance\n",
    "\n",
    "\n",
    "def process_midi(midi_path):\n",
    "    \"\"\"\n",
    "    Wrapper function to process MIDI files, extract tokens, and encode them.\n",
    "    Returns a tuple: (raw MIDI tokens, encoded MIDI tokens).\n",
    "    \"\"\"\n",
    "    midi_tokens = midi_to_token_sequence(midi_path)  # Extract raw MIDI tokens\n",
    "    encoded_tokens = midi_vocab.encode(midi_tokens) if midi_tokens else None  # Encode if valid tokens exist\n",
    "    return midi_tokens, encoded_tokens  # Store both\n",
    "\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel processing\n",
    "with ThreadPoolExecutor(max_workers=12) as executor:  # Adjust max_workers as needed\n",
    "    futures = {executor.submit(process_midi, row[\".midi\"]): idx for idx, row in music_df.iterrows() if\n",
    "               pd.notna(row[\".midi\"])}\n",
    "\n",
    "    # Collect results and store them in the DataFrame\n",
    "    for future in as_completed(futures):\n",
    "        idx = futures[future]\n",
    "        try:\n",
    "            raw_tokens, encoded_tokens = future.result()  # Get processed tokens\n",
    "\n",
    "            # Ensure lists are stored properly as objects to avoid NumPy conversion errors\n",
    "            music_df.at[idx, \"MIDI_Tokens\"] = raw_tokens if raw_tokens is None else list(raw_tokens)\n",
    "            music_df.at[idx, \"Encoded_MIDI_Tokens\"] = encoded_tokens if encoded_tokens is None else list(encoded_tokens)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing MIDI file at row {idx}: {e}\")\n",
    "\n",
    "#  Explicitly convert columns to object type again to be safe\n",
    "music_df[\"MIDI_Tokens\"] = music_df[\"MIDI_Tokens\"].astype(\"object\")\n",
    "music_df[\"Encoded_MIDI_Tokens\"] = music_df[\"Encoded_MIDI_Tokens\"].astype(\"object\")\n",
    "\n",
    "# Print to verify\n",
    "print(music_df.head())  # Display the first few rows\n",
    "print(f\"Processed {music_df['MIDI_Tokens'].notnull().sum()} MIDI files successfully.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "music_df",
   "id": "be73f4804e0aa917",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "music_df.to_pickle(\"music_data.pkl\")",
   "id": "413d94ff99046145",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T11:49:08.644079Z",
     "start_time": "2025-04-30T11:48:50.191331Z"
    }
   },
   "cell_type": "code",
   "source": "music_df = pd.read_pickle(\"music_data.pkl\")",
   "id": "a5fb6288e1d2e081",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def snap_to_fraction(timestamps, resolution=480, tempo=120):\n",
    "    \"\"\"\n",
    "    Convert float timestamps into rational fractions of MIDI ticks.\n",
    "    \"\"\"\n",
    "    if not isinstance(timestamps, (list, np.ndarray)):\n",
    "        return None\n",
    "    ticks_per_second = Fraction(resolution * tempo, 60)\n",
    "    return [Fraction(str(t)) * ticks_per_second for t in timestamps]\n"
   ],
   "id": "56818f44f9bb497b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "symbolic_df = pd.DataFrame()\n",
    "symbolic_df[\"MIDI_Notes\"] = music_df[\"MIDI_Notes\"]\n",
    "symbolic_df[\"MIDI_Timestamps_Fraction\"] = music_df[\"MIDI_Timestamps\"].apply(snap_to_fraction)\n",
    "symbolic_df.to_pickle(\"symbolic_midi_data.pkl\")\n",
    "symbolic_df[\"MIDI_Ticks\"] = symbolic_df[\"MIDI_Timestamps_Fraction\"].apply(lambda ts: [int(round(t)) for t in ts] if ts else None)"
   ],
   "id": "6130892496f84d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "symbolic_df.to_pickle(\"symbolic_midi_data.pkl\")\n",
    "symbolic_df"
   ],
   "id": "a31178f5aac26c50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "music_df",
   "id": "5ecfbe54e66be425",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "320d5abae19669a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T11:49:08.837021Z",
     "start_time": "2025-04-30T11:49:08.789456Z"
    }
   },
   "source": [
    "# Ensure required directories exist\n",
    "# Directory to cache spectrogram tensors\n",
    "spectrogram_cache_dir = \"spectrogram_cache\"\n",
    "\n",
    "# Directory to cache spectrogram images\n",
    "image_cache_dir = \"spectrogram_images\"\n",
    "\n",
    "# Ensure the directories exist or create them if they don't\n",
    "os.makedirs(spectrogram_cache_dir, exist_ok=True)\n",
    "os.makedirs(image_cache_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def process_wav_to_spectrogram(wav_file_path, file_index, device, bins_per_octave=24, n_bins=192, hop_length=256):\n",
    "    \"\"\"\n",
    "    Converts a WAV file into a multi-view spectrogram tensor and saves it to disk.\n",
    "\n",
    "    Args:\n",
    "        wav_file_path (str): Path to the input WAV file.\n",
    "        file_index (int): Index representing the specific file being processed (used for caching).\n",
    "        device (torch.device): Device (CPU or GPU) to perform computations on.\n",
    "        bins_per_octave (int): Number of frequency bins per octave (default = 24).\n",
    "        n_bins (int): Total number of frequency bins (default = 192).\n",
    "        hop_length (int): Hop length for the spectrogram calculation (default = 256).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (str or None, None)\n",
    "        - Path to the saved spectrogram file if successful, None otherwise.\n",
    "\n",
    "    Raises:\n",
    "        Exception: Handles exceptions during processing and returns (None, None).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio_signal, sample_rate = librosa.load(wav_file_path, sr=None)\n",
    "        if np.all(audio_signal == 0):\n",
    "            print(f\"‚ö†Ô∏è Silent audio detected: {wav_file_path}\")\n",
    "            return None, None\n",
    "\n",
    "        # Normalize and pre-process\n",
    "        audio_signal = torch.tensor(audio_signal, dtype=torch.float32, device=device)\n",
    "        audio_signal = audio_signal / (torch.max(torch.abs(audio_signal)) + 1e-6)\n",
    "\n",
    "        # Loudness normalization\n",
    "        import pyloudnorm as pyln\n",
    "        loudness_meter = pyln.Meter(sample_rate)\n",
    "        audio_signal_np = audio_signal.cpu().numpy()\n",
    "        integrated_loudness = loudness_meter.integrated_loudness(audio_signal_np)\n",
    "        audio_signal_np = pyln.normalize.loudness(audio_signal_np, integrated_loudness, -27.0)\n",
    "\n",
    "        # Back to torch\n",
    "        audio_signal = torch.tensor(audio_signal_np, dtype=torch.float32, device=device)\n",
    "        audio_signal = torch.clamp(audio_signal, -0.85, 0.85)\n",
    "\n",
    "        # Pre-emphasis\n",
    "        audio_signal_np = librosa.effects.preemphasis(audio_signal.cpu().numpy())\n",
    "        audio_signal = torch.tensor(audio_signal_np, dtype=torch.float32, device=device)\n",
    "\n",
    "        # Harmonic/Percussive separation\n",
    "        harmonic_signal, percussive_signal = librosa.effects.hpss(audio_signal.cpu().numpy())\n",
    "        harmonic_signal, percussive_signal = torch.tensor(harmonic_signal), torch.tensor(percussive_signal)\n",
    "\n",
    "        def normalize_to_db(spectrogram):\n",
    "            \"\"\"\n",
    "            Normalizes a given spectrogram to dB scale between 0 and 1.\n",
    "\n",
    "            Args:\n",
    "                spectrogram (np.ndarray): Input spectrogram to normalize.\n",
    "\n",
    "            Returns:\n",
    "                np.ndarray: Normalized spectrogram.\n",
    "            \"\"\"\n",
    "            db_values = librosa.amplitude_to_db(spectrogram, ref=np.max)\n",
    "            return (db_values - db_values.min()) / (db_values.max() - db_values.min() + 1e-6)\n",
    "\n",
    "        # === Spectrogram Features ===\n",
    "        spectrogram_features = [\n",
    "            normalize_to_db(np.abs(librosa.cqt(harmonic_signal.numpy(), sr=sample_rate, hop_length=hop_length, n_bins=n_bins, bins_per_octave=bins_per_octave))),\n",
    "            normalize_to_db(np.abs(librosa.cqt(percussive_signal.numpy(), sr=sample_rate, hop_length=hop_length, n_bins=n_bins, bins_per_octave=bins_per_octave))),\n",
    "            normalize_to_db(librosa.feature.melspectrogram(y=audio_signal.cpu().numpy(), sr=sample_rate, hop_length=hop_length, n_mels=128)),\n",
    "            normalize_to_db(librosa.feature.mfcc(y=audio_signal.cpu().numpy(), sr=sample_rate, n_mfcc=20)),\n",
    "            normalize_to_db(librosa.feature.chroma_cqt(y=audio_signal.cpu().numpy(), sr=sample_rate, hop_length=hop_length)),\n",
    "            normalize_to_db(librosa.feature.spectral_contrast(y=audio_signal.cpu().numpy(), sr=sample_rate, hop_length=hop_length)),\n",
    "            normalize_to_db(librosa.feature.tonnetz(y=librosa.effects.harmonic(audio_signal.cpu().numpy()), sr=sample_rate)),\n",
    "            normalize_to_db(librosa.feature.rms(y=audio_signal.cpu().numpy())),\n",
    "            normalize_to_db(librosa.feature.zero_crossing_rate(audio_signal.cpu().numpy())),\n",
    "            normalize_to_db(librosa.onset.onset_strength(y=audio_signal.cpu().numpy(), sr=sample_rate, hop_length=hop_length).reshape(1, -1)),  # reshape to 2D\n",
    "            normalize_to_db(librosa.feature.tempogram(y=audio_signal.cpu().numpy(), sr=sample_rate, hop_length=hop_length)),\n",
    "        ]\n",
    "\n",
    "        # Align time dimension\n",
    "        min_time_dim = min(feature.shape[1] for feature in spectrogram_features)\n",
    "        spectrogram_features = [feature[:, :min_time_dim] for feature in spectrogram_features]\n",
    "\n",
    "        # Pad frequency dimension\n",
    "        max_freq_bins = max(feature.shape[0] for feature in spectrogram_features)\n",
    "        spectrogram_features = [np.pad(feature, ((0, max_freq_bins - feature.shape[0]), (0, 0)), mode='constant') for feature in spectrogram_features]\n",
    "\n",
    "        # Stack all together: shape ‚Üí [channels, freq_bins, time_steps]\n",
    "        spectrogram_tensor = torch.tensor(np.stack(spectrogram_features), dtype=torch.float32)\n",
    "\n",
    "        # Save\n",
    "        spectrogram_path = os.path.join(spectrogram_cache_dir, f\"{file_index}.pkl\")\n",
    "        torch.save(spectrogram_tensor, spectrogram_path)\n",
    "\n",
    "\n",
    "        # Cleanup\n",
    "        del audio_signal, harmonic_signal, percussive_signal, spectrogram_features, spectrogram_tensor\n",
    "        time.sleep(1.0)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        return spectrogram_path, None\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f\"‚ùå Error processing {wav_file_path}: {error}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        return None, None"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T11:49:08.952015Z",
     "start_time": "2025-04-30T11:49:08.944149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "empty_rows = music_df.isna().all(axis=1)  # Find rows where all columns are NaN\n",
    "print(f\"Number of fully empty rows: {empty_rows.sum()}\")\n",
    "print(music_df[empty_rows])  # Display problematic rows\n",
    "print(music_df[[\".midi\", \".wav\"]].isna().sum())"
   ],
   "id": "9d2dd59a769c3202",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fully empty rows: 0\n",
      "Empty DataFrame\n",
      "Columns: [.midi, .wav, WAV_Notes, WAV_Timestamps, MIDI_Notes, MIDI_Timestamps, WAV_Notes_Clean, WAV_Timestamps_Snapped, MIDI_Timestamps_Snapped, WAV_Timestamp_Real+Tick, MIDI_Tokens, Encoded_MIDI_Tokens, Spectrogram_Path, Spectrogram_Image]\n",
      "Index: []\n",
      ".midi    0\n",
      ".wav     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T11:49:09.017205Z",
     "start_time": "2025-04-30T11:49:09.012308Z"
    }
   },
   "cell_type": "code",
   "source": "music_df = music_df.dropna(how=\"all\")",
   "id": "8407fb195f6a424b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T11:49:09.083583Z",
     "start_time": "2025-04-30T11:49:09.076870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "empty_rows = music_df.isna().all(axis=1)  # Find rows where all columns are NaN\n",
    "print(f\"Number of fully empty rows: {empty_rows.sum()}\")\n",
    "print(music_df[empty_rows])  # Display problematic rows\n",
    "print(music_df[[\".midi\", \".wav\"]].isna().sum())"
   ],
   "id": "4c0a153192c67a58",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fully empty rows: 0\n",
      "Empty DataFrame\n",
      "Columns: [.midi, .wav, WAV_Notes, WAV_Timestamps, MIDI_Notes, MIDI_Timestamps, WAV_Notes_Clean, WAV_Timestamps_Snapped, MIDI_Timestamps_Snapped, WAV_Timestamp_Real+Tick, MIDI_Tokens, Encoded_MIDI_Tokens, Spectrogram_Path, Spectrogram_Image]\n",
      "Index: []\n",
      ".midi    0\n",
      ".wav     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Path configuration for storing model artifacts\n",
    "spectrogram_cache_dir = Path(\"spectrogram_cache\")\n",
    "image_cache_dir = Path(\"spectrogram_images\")\n",
    "spectrogram_cache_dir.mkdir(exist_ok=True)\n",
    "image_cache_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Set device based on hardware availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Configuration parameters for memory management and processing\n",
    "initial_batch_size = 10  # Initial size of processing batches\n",
    "min_batch_size = 10  # Lower bound for batch size\n",
    "memory_threshold = 0.8  # Threshold for high memory usage (80%)\n",
    "recovery_threshold = 0.3  # Threshold for memory recovery (30%)\n",
    "max_workers = 12  # Maximum number of parallel processing threads\n",
    "\n",
    "# Initialize output path storage\n",
    "spectrogram_paths, image_paths = [], []\n",
    "\n",
    "\n",
    "def get_available_ram():\n",
    "    \"\"\"Return the current available RAM as a percentage of total RAM.\"\"\"\n",
    "    return psutil.virtual_memory().available / psutil.virtual_memory().total\n",
    "\n",
    "\n",
    "def validate_spectrogram(path):\n",
    "    \"\"\"\n",
    "    Validate the integrity of a spectrogram file.\n",
    "\n",
    "    Args:\n",
    "        path (Path): Path to the spectrogram file.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if spectrogram is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if path.suffix == \".pt\":\n",
    "            tensor = torch.load(path, map_location=\"cuda\")\n",
    "        else:\n",
    "            with open(path, \"rb\") as f:\n",
    "                tensor = torch.load(f, map_location=\"cuda\")\n",
    "        return isinstance(tensor, torch.Tensor) and tensor.ndim >= 2\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Validation failed for {path}: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def scan_and_fix_spectrogram_cache(music_df):\n",
    "    \"\"\"\n",
    "    Scan the spectrogram cache for invalid or corrupted files.\n",
    "\n",
    "    Args:\n",
    "        music_df (pd.DataFrame): DataFrame containing spectrogram metadata.\n",
    "\n",
    "    Returns:\n",
    "        list: Indices of rows with bad or missing spectrograms.\n",
    "    \"\"\"\n",
    "    print(\"üîç Scanning spectrogram cache for invalid files...\")\n",
    "    bad_files = []\n",
    "    for idx, row in music_df.iterrows():\n",
    "        path = Path(row.get(\"Spectrogram_Path\", \"\"))\n",
    "        if path.is_file():\n",
    "            if not validate_spectrogram(path):\n",
    "                bad_files.append(idx)\n",
    "                try:\n",
    "                    path.unlink()\n",
    "                    print(f\"üóëÔ∏è Deleted corrupt spectrogram at {path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Failed to delete {path}: {e}\")\n",
    "        else:\n",
    "            bad_files.append(idx)\n",
    "    print(f\"‚úÖ Scan complete. Found {len(bad_files)} bad or missing spectrograms.\")\n",
    "    return bad_files\n",
    "\n",
    "\n",
    "def regenerate_spectrograms(music_df, bad_indices):\n",
    "    \"\"\"\n",
    "    Regenerate missing or corrupted spectrograms.\n",
    "\n",
    "    Args:\n",
    "        music_df (pd.DataFrame): DataFrame containing audio file information.\n",
    "        bad_indices (list): List of indices for spectrograms that need regeneration.\n",
    "    \"\"\"\n",
    "    print(f\"üîÑ Regenerating {len(bad_indices)} missing/corrupt spectrograms...\")\n",
    "    batch_size = initial_batch_size\n",
    "    i = 0\n",
    "    bad_rows = music_df.loc[bad_indices]\n",
    "    while i < len(bad_rows):\n",
    "        # Dynamic batch size adjustment based on memory usage\n",
    "        available_ram = get_available_ram()\n",
    "        if available_ram < memory_threshold and batch_size > min_batch_size:\n",
    "            batch_size = max(min_batch_size, int(batch_size * 0.8))\n",
    "            print(f\"‚ö†Ô∏è High memory usage detected! Reducing batch size to {batch_size}\")\n",
    "        elif available_ram > recovery_threshold and batch_size < initial_batch_size:\n",
    "            batch_size = min(initial_batch_size, int(batch_size * 1.1))\n",
    "            print(f\"‚úÖ Memory recovered. Increasing batch size to {batch_size}\")\n",
    "\n",
    "        batch = bad_rows.iloc[i: i + batch_size]\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = {\n",
    "                executor.submit(process_wav_to_spectrogram, row[\".wav\"], idx, device): idx\n",
    "                for idx, row in batch.iterrows() if pd.notna(row.get(\".wav\"))\n",
    "            }\n",
    "            for future in as_completed(futures):\n",
    "                idx = futures[future]\n",
    "                try:\n",
    "                    tensor_path, image_path = future.result()\n",
    "                    if tensor_path:\n",
    "                        music_df.at[idx, \"Spectrogram_Path\"] = tensor_path\n",
    "                    if image_path:\n",
    "                        music_df.at[idx, \"Spectrogram_Image\"] = image_path\n",
    "                    print(f\"‚úÖ Regenerated spectrogram for {idx}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Failed to regenerate {idx}: {e}\")\n",
    "\n",
    "        # Clean up resources after batch processing\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        i += batch_size\n",
    "        time.sleep(0.5)\n",
    "    print(\"üèÅ Regeneration complete.\")\n",
    "\n",
    "\n",
    "# Main execution flow\n",
    "bad_indices = scan_and_fix_spectrogram_cache(music_df)\n",
    "if bad_indices:\n",
    "    regenerate_spectrograms(music_df, bad_indices)\n",
    "else:\n",
    "    print(\"üéØ No missing or corrupt spectrograms to fix!\")\n",
    "\n",
    "# Save the updated DataFrame\n",
    "music_df.to_pickle(\"music_df_fixed.pkl\")\n",
    "print(\"üíæ Saved repaired DataFrame to music_df_fixed.pkl\")"
   ],
   "id": "b2c8300f0b6a0ce0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_01_R1_2015_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_02_R1_2015_wav--6\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_01_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_01_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_02_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_03_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_04_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_04_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_04_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_04_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_05_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_03_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_05_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_03_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_03_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_06_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_06_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_06_R1_2015_wav--6\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_06_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_05_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_06_R1_2015_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_07_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_05_R1_2015_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_05_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_06_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_07_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_09_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_09_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_08_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_08_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_07_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_08_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_07_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-1-8_mid--AUDIO-from_mp3_08_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_09_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_11_R1_2015_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_10_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_11_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_11_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_12_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_11_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_09_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_10_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_11_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_10_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_12_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_13_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_12_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_12_R1_2015_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_13_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_14_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_14_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_14_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_13_R1_2015_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D1-9-12_mid--AUDIO-from_mp3_12_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_15_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_14_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_16_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_16_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_16_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_15_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_15_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_15_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_16_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_15_R1_2015_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_18_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_17_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_17_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_17_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_18_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_17_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_18_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_18_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_20_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-21-22_mid--AUDIO-from_mp3_21_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-21-22_mid--AUDIO-from_mp3_21_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_19_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_20_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_20_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-21-22_mid--AUDIO-from_mp3_21_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-21-22_mid--AUDIO-from_mp3_21_R1_2015_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-13-20_mid--AUDIO-from_mp3_20_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D1-2-3-6-7-8-11_mid--AUDIO-from_mp3_03_R2_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-21-22_mid--AUDIO-from_mp3_22_R1_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-21-22_mid--AUDIO-from_mp3_22_R1_2015_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-21-22_mid--AUDIO-from_mp3_22_R1_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D1-2-3-6-7-8-11_mid--AUDIO-from_mp3_06_R2_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-21-22_mid--AUDIO-from_mp3_22_R1_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R1_D2-21-22_mid--AUDIO-from_mp3_22_R1_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D1-2-3-6-7-8-11_mid--AUDIO-from_mp3_06_R2_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D1-2-3-6-7-8-11_mid--AUDIO-from_mp3_06_R2_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D1-2-3-6-7-8-11_mid--AUDIO-from_mp3_03_R2_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D1-2-3-6-7-8-11_mid--AUDIO-from_mp3_11_R2_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D1-2-3-6-7-8-11_mid--AUDIO-from_mp3_07_R2_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D1-2-3-6-7-8-11_mid--AUDIO-from_mp3_08_R2_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-12-13-15_mid--AUDIO-from_mp3_12_R2_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D1-2-3-6-7-8-11_mid--AUDIO-from_mp3_08_R2_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D1-2-3-6-7-8-11_mid--AUDIO-from_mp3_08_R2_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D1-2-3-6-7-8-11_mid--AUDIO-from_mp3_07_R2_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D1-2-3-6-7-8-11_mid--AUDIO-from_mp3_11_R2_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D1-2-3-6-7-8-11_mid--AUDIO-from_mp3_07_R2_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D1-2-3-6-7-8-11_mid--AUDIO-from_mp3_11_R2_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-12-13-15_mid--AUDIO-from_mp3_13_R2_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-12-13-15_mid--AUDIO-from_mp3_15_R2_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-12-13-15_mid--AUDIO-from_mp3_12_R2_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-12-13-15_mid--AUDIO-from_mp3_12_R2_2015_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-12-13-15_mid--AUDIO-from_mp3_13_R2_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-12-13-15_mid--AUDIO-from_mp3_13_R2_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-12-13-15_mid--AUDIO-from_mp3_15_R2_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-19-21-22_mid--AUDIO-from_mp3_19_R2_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-12-13-15_mid--AUDIO-from_mp3_12_R2_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-12-13-15_mid--AUDIO-from_mp3_15_R2_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_041_PIANO041_MID--AUDIO-split_07-06-17_Piano-e_1-01_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-19-21-22_mid--AUDIO-from_mp3_22_R2_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-19-21-22_mid--AUDIO-from_mp3_19_R2_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-19-21-22_mid--AUDIO-from_mp3_21_R2_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-19-21-22_mid--AUDIO-from_mp3_22_R2_2015_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-19-21-22_mid--AUDIO-from_mp3_19_R2_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-19-21-22_mid--AUDIO-from_mp3_21_R2_2015_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-19-21-22_mid--AUDIO-from_mp3_21_R2_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-19-21-22_mid--AUDIO-from_mp3_22_R2_2015_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_R2_D2-19-21-22_mid--AUDIO-from_mp3_22_R2_2015_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_043_PIANO043_MID--AUDIO-split_07-06-17_Piano-e_1-03_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_042_PIANO042_MID--AUDIO-split_07-06-17_Piano-e_1-02_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_041_PIANO041_MID--AUDIO-split_07-06-17_Piano-e_1-01_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_042_PIANO042_MID--AUDIO-split_07-06-17_Piano-e_1-02_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_042_PIANO042_MID--AUDIO-split_07-06-17_Piano-e_1-02_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_043_PIANO043_MID--AUDIO-split_07-06-17_Piano-e_1-03_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_043_PIANO043_MID--AUDIO-split_07-06-17_Piano-e_1-03_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_041_PIANO041_MID--AUDIO-split_07-06-17_Piano-e_1-01_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_043_PIANO043_MID--AUDIO-split_07-06-17_Piano-e_1-03_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_041_PIANO041_MID--AUDIO-split_07-06-17_Piano-e_1-01_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_044_PIANO044_MID--AUDIO-split_07-06-17_Piano-e_1-04_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_046_PIANO046_MID--AUDIO-split_07-06-17_Piano-e_2-02_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_046_PIANO046_MID--AUDIO-split_07-06-17_Piano-e_2-02_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_045_PIANO045_MID--AUDIO-split_07-06-17_Piano-e_2-01_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_044_PIANO044_MID--AUDIO-split_07-06-17_Piano-e_1-04_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_044_PIANO044_MID--AUDIO-split_07-06-17_Piano-e_1-04_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_045_PIANO045_MID--AUDIO-split_07-06-17_Piano-e_2-01_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_045_PIANO045_MID--AUDIO-split_07-06-17_Piano-e_2-01_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_046_PIANO046_MID--AUDIO-split_07-06-17_Piano-e_2-02_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_044_PIANO044_MID--AUDIO-split_07-06-17_Piano-e_1-04_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_047_PIANO047_MID--AUDIO-split_07-06-17_Piano-e_2-04_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_049_PIANO049_MID--AUDIO-split_07-06-17_Piano-e_2-06_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_049_PIANO049_MID--AUDIO-split_07-06-17_Piano-e_2-06_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_047_PIANO047_MID--AUDIO-split_07-06-17_Piano-e_2-04_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_048_PIANO048_MID--AUDIO-split_07-06-17_Piano-e_2-05_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_047_PIANO047_MID--AUDIO-split_07-06-17_Piano-e_2-04_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_048_PIANO048_MID--AUDIO-split_07-06-17_Piano-e_2-05_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_047_PIANO047_MID--AUDIO-split_07-06-17_Piano-e_2-04_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_046_PIANO046_MID--AUDIO-split_07-06-17_Piano-e_2-02_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_048_PIANO048_MID--AUDIO-split_07-06-17_Piano-e_2-05_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_049_PIANO049_MID--AUDIO-split_07-06-17_Piano-e_2-06_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_049_PIANO049_MID--AUDIO-split_07-06-17_Piano-e_2-06_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_050_PIANO050_MID--AUDIO-split_07-06-17_Piano-e_3-01_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_050_PIANO050_MID--AUDIO-split_07-06-17_Piano-e_3-01_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_050_PIANO050_MID--AUDIO-split_07-06-17_Piano-e_3-01_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_050_PIANO050_MID--AUDIO-split_07-06-17_Piano-e_3-01_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_049_PIANO049_MID--AUDIO-split_07-06-17_Piano-e_2-06_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_053_PIANO053_MID--AUDIO-split_07-06-17_Piano-e_3-04_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_053_PIANO053_MID--AUDIO-split_07-06-17_Piano-e_3-04_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_052_PIANO052_MID--AUDIO-split_07-06-17_Piano-e_3-03_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_052_PIANO052_MID--AUDIO-split_07-06-17_Piano-e_3-03_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_052_PIANO052_MID--AUDIO-split_07-06-17_Piano-e_3-03_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_053_PIANO053_MID--AUDIO-split_07-06-17_Piano-e_3-04_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_052_PIANO052_MID--AUDIO-split_07-06-17_Piano-e_3-03_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_051_PIANO051_MID--AUDIO-split_07-06-17_Piano-e_3-02_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_053_PIANO053_MID--AUDIO-split_07-06-17_Piano-e_3-04_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_056_PIANO056_MID--AUDIO-split_07-07-17_Piano-e_1-05_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_054_PIANO054_MID--AUDIO-split_07-07-17_Piano-e_1-02_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_054_PIANO054_MID--AUDIO-split_07-07-17_Piano-e_1-02_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_055_PIANO055_MID--AUDIO-split_07-07-17_Piano-e_1-04_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_056_PIANO056_MID--AUDIO-split_07-07-17_Piano-e_1-05_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_055_PIANO055_MID--AUDIO-split_07-07-17_Piano-e_1-04_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_054_PIANO054_MID--AUDIO-split_07-07-17_Piano-e_1-02_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_055_PIANO055_MID--AUDIO-split_07-07-17_Piano-e_1-04_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_056_PIANO056_MID--AUDIO-split_07-07-17_Piano-e_1-05_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_054_PIANO054_MID--AUDIO-split_07-07-17_Piano-e_1-02_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_058_PIANO058_MID--AUDIO-split_07-07-17_Piano-e_2-02_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_057_PIANO057_MID--AUDIO-split_07-07-17_Piano-e_1-07_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_057_PIANO057_MID--AUDIO-split_07-07-17_Piano-e_1-07_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_058_PIANO058_MID--AUDIO-split_07-07-17_Piano-e_2-02_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_057_PIANO057_MID--AUDIO-split_07-07-17_Piano-e_1-07_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_058_PIANO058_MID--AUDIO-split_07-07-17_Piano-e_2-02_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_057_PIANO057_MID--AUDIO-split_07-07-17_Piano-e_1-07_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_058_PIANO058_MID--AUDIO-split_07-07-17_Piano-e_2-02_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_056_PIANO056_MID--AUDIO-split_07-07-17_Piano-e_1-05_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_057_PIANO057_MID--AUDIO-split_07-07-17_Piano-e_1-07_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_060_PIANO060_MID--AUDIO-split_07-07-17_Piano-e_2-04_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_059_PIANO059_MID--AUDIO-split_07-07-17_Piano-e_2-03_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_060_PIANO060_MID--AUDIO-split_07-07-17_Piano-e_2-04_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_060_PIANO060_MID--AUDIO-split_07-07-17_Piano-e_2-04_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_059_PIANO059_MID--AUDIO-split_07-07-17_Piano-e_2-03_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_058_PIANO058_MID--AUDIO-split_07-07-17_Piano-e_2-02_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_060_PIANO060_MID--AUDIO-split_07-07-17_Piano-e_2-04_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_059_PIANO059_MID--AUDIO-split_07-07-17_Piano-e_2-03_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_060_PIANO060_MID--AUDIO-split_07-07-17_Piano-e_2-04_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_059_PIANO059_MID--AUDIO-split_07-07-17_Piano-e_2-03_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_062_PIANO062_MID--AUDIO-split_07-07-17_Piano-e_2-07_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_062_PIANO062_MID--AUDIO-split_07-07-17_Piano-e_2-07_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_065_PIANO065_MID--AUDIO-split_07-07-17_Piano-e_3-01_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_061_PIANO061_MID--AUDIO-split_07-07-17_Piano-e_2-05_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_065_PIANO065_MID--AUDIO-split_07-07-17_Piano-e_3-01_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_061_PIANO061_MID--AUDIO-split_07-07-17_Piano-e_2-05_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_065_PIANO065_MID--AUDIO-split_07-07-17_Piano-e_3-01_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_062_PIANO062_MID--AUDIO-split_07-07-17_Piano-e_2-07_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_062_PIANO062_MID--AUDIO-split_07-07-17_Piano-e_2-07_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_061_PIANO061_MID--AUDIO-split_07-07-17_Piano-e_2-05_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_070_PIANO070_MID--AUDIO-split_07-08-17_Piano-e_1-02_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_067_PIANO067_MID--AUDIO-split_07-07-17_Piano-e_3-03_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_067_PIANO067_MID--AUDIO-split_07-07-17_Piano-e_3-03_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_070_PIANO070_MID--AUDIO-split_07-08-17_Piano-e_1-02_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_066_PIANO066_MID--AUDIO-split_07-07-17_Piano-e_3-02_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_067_PIANO067_MID--AUDIO-split_07-07-17_Piano-e_3-03_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_066_PIANO066_MID--AUDIO-split_07-07-17_Piano-e_3-02_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_066_PIANO066_MID--AUDIO-split_07-07-17_Piano-e_3-02_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_067_PIANO067_MID--AUDIO-split_07-07-17_Piano-e_3-03_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_066_PIANO066_MID--AUDIO-split_07-07-17_Piano-e_3-02_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_071_PIANO071_MID--AUDIO-split_07-08-17_Piano-e_1-04_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_071_PIANO071_MID--AUDIO-split_07-08-17_Piano-e_1-04_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_072_PIANO072_MID--AUDIO-split_07-08-17_Piano-e_1-06_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_072_PIANO072_MID--AUDIO-split_07-08-17_Piano-e_1-06_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_072_PIANO072_MID--AUDIO-split_07-08-17_Piano-e_1-06_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_071_PIANO071_MID--AUDIO-split_07-08-17_Piano-e_1-04_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_073_PIANO073_MID--AUDIO-split_07-08-17_Piano-e_2-02_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_072_PIANO072_MID--AUDIO-split_07-08-17_Piano-e_1-06_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_070_PIANO070_MID--AUDIO-split_07-08-17_Piano-e_1-02_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_071_PIANO071_MID--AUDIO-split_07-08-17_Piano-e_1-04_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_075_PIANO075_MID--AUDIO-split_07-08-17_Piano-e_2-06_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_073_PIANO073_MID--AUDIO-split_07-08-17_Piano-e_2-02_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_075_PIANO075_MID--AUDIO-split_07-08-17_Piano-e_2-06_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_078_PIANO078_MID--AUDIO-split_07-09-17_Piano-e_1-02_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_075_PIANO075_MID--AUDIO-split_07-08-17_Piano-e_2-06_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_074_PIANO074_MID--AUDIO-split_07-08-17_Piano-e_2-04_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_074_PIANO074_MID--AUDIO-split_07-08-17_Piano-e_2-04_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_078_PIANO078_MID--AUDIO-split_07-09-17_Piano-e_1-02_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_073_PIANO073_MID--AUDIO-split_07-08-17_Piano-e_2-02_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_074_PIANO074_MID--AUDIO-split_07-08-17_Piano-e_2-04_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_079_PIANO079_MID--AUDIO-split_07-09-17_Piano-e_1-04_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_080_PIANO080_MID--AUDIO-split_07-09-17_Piano-e_1-06_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_081_PIANO081_MID--AUDIO-split_07-09-17_Piano-e_2_-02_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_079_PIANO079_MID--AUDIO-split_07-09-17_Piano-e_1-04_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_081_PIANO081_MID--AUDIO-split_07-09-17_Piano-e_2_-02_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_080_PIANO080_MID--AUDIO-split_07-09-17_Piano-e_1-06_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_079_PIANO079_MID--AUDIO-split_07-09-17_Piano-e_1-04_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_078_PIANO078_MID--AUDIO-split_07-09-17_Piano-e_1-02_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_079_PIANO079_MID--AUDIO-split_07-09-17_Piano-e_1-04_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_080_PIANO080_MID--AUDIO-split_07-09-17_Piano-e_1-06_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_083_PIANO083_MID--AUDIO-split_07-09-17_Piano-e_2_-06_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_083_PIANO083_MID--AUDIO-split_07-09-17_Piano-e_2_-06_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_083_PIANO083_MID--AUDIO-split_07-09-17_Piano-e_2_-06_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_083_PIANO083_MID--AUDIO-split_07-09-17_Piano-e_2_-06_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_082_PIANO082_MID--AUDIO-split_07-09-17_Piano-e_2_-04_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_081_PIANO081_MID--AUDIO-split_07-09-17_Piano-e_2_-02_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Chamber2_MID--AUDIO_09_R3_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_082_PIANO082_MID--AUDIO-split_07-09-17_Piano-e_2_-04_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_083_PIANO083_MID--AUDIO-split_07-09-17_Piano-e_2_-06_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_082_PIANO082_MID--AUDIO-split_07-09-17_Piano-e_2_-04_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Chamber6_MID--AUDIO_20_R3_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Chamber4_MID--AUDIO_11_R3_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Chamber6_MID--AUDIO_20_R3_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Chamber5_MID--AUDIO_18_R3_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital1-3_MID--AUDIO_03_R1_2018_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital1-3_MID--AUDIO_03_R1_2018_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital12_MID--AUDIO_12_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital12_MID--AUDIO_12_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital1-3_MID--AUDIO_03_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital1-3_MID--AUDIO_03_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital13-15_MID--AUDIO_15_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital13-15_MID--AUDIO_14_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital13-15_MID--AUDIO_15_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital12_MID--AUDIO_12_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital13-15_MID--AUDIO_14_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital13-15_MID--AUDIO_14_R1_2018_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital13-15_MID--AUDIO_13_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital13-15_MID--AUDIO_14_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital13-15_MID--AUDIO_13_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital13-15_MID--AUDIO_13_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital17-19_MID--AUDIO_17_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital17-19_MID--AUDIO_17_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital16_MID--AUDIO_16_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital17-19_MID--AUDIO_18_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital16_MID--AUDIO_16_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital17-19_MID--AUDIO_17_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital17-19_MID--AUDIO_18_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital13-15_MID--AUDIO_15_R1_2018_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital13-15_MID--AUDIO_15_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital17-19_MID--AUDIO_17_R1_2018_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital17-19_MID--AUDIO_18_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital17-19_MID--AUDIO_19_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital17-19_MID--AUDIO_19_R1_2018_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital4_MID--AUDIO_04_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital17-19_MID--AUDIO_19_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital17-19_MID--AUDIO_19_R1_2018_wav--6\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital20_MID--AUDIO_20_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital17-19_MID--AUDIO_19_R1_2018_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital17-19_MID--AUDIO_19_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital20_MID--AUDIO_20_R1_2018_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital4_MID--AUDIO_04_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital4_MID--AUDIO_04_R1_2018_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital5-7_MID--AUDIO_07_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital5-7_MID--AUDIO_05_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital5-7_MID--AUDIO_06_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital5-7_MID--AUDIO_05_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital5-7_MID--AUDIO_06_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital5-7_MID--AUDIO_06_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital5-7_MID--AUDIO_05_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital4_MID--AUDIO_04_R1_2018_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital9-11_MID--AUDIO_09_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital5-7_MID--AUDIO_07_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital9-11_MID--AUDIO_09_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital8_MID--AUDIO_08_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital8_MID--AUDIO_08_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital8_MID--AUDIO_08_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital5-7_MID--AUDIO_07_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital9-11_MID--AUDIO_09_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital5-7_MID--AUDIO_07_R1_2018_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital8_MID--AUDIO_08_R1_2018_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital9-11_MID--AUDIO_09_R1_2018_wav--6\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital9-11_MID--AUDIO_09_R1_2018_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital9-11_MID--AUDIO_09_R1_2018_wav--4\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital9-11_MID--AUDIO_10_R1_2018_wav--3\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital9-11_MID--AUDIO_11_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital9-11_MID--AUDIO_10_R1_2018_wav--1\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital9-11_MID--AUDIO_10_R1_2018_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital9-11_MID--AUDIO_10_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital9-11_MID--AUDIO_11_R1_2018_wav--2\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Recital9-11_MID--AUDIO_11_R1_2018_wav--5\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Schubert4-6_MID--AUDIO_08_R2_2018_wav\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Schubert1-3_MID--AUDIO_05_R2_2018_wav\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Schubert7-9_MID--AUDIO_11_R2_2018_wav\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Schubert1-3_MID--AUDIO_02_R2_2018_wav\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Schubert10-12_MID--AUDIO_17_R2_2018_wav\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Schubert10-12_MID--AUDIO_18_R2_2018_wav\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Schubert1-3_MID--AUDIO_07_R2_2018_wav\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Schubert10-12_MID--AUDIO_20_R2_2018_wav\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Schubert4-6_MID--AUDIO_10_R2_2018_wav\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Schubert4-6_MID--AUDIO_09_R2_2018_wav\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Schubert7-9_MID--AUDIO_16_R2_2018_wav\n",
      "‚úÖ Regenerated spectrogram for MIDI-Unprocessed_Schubert7-9_MID--AUDIO_15_R2_2018_wav\n",
      "üèÅ Regeneration complete.\n",
      "üíæ Saved repaired DataFrame to music_df_fixed.pkl\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Validate and clean spectrogram cache files \n",
    "spectrogram_dir = Path(\"spectrogram_cache\")\n",
    "bad_spectrograms = []\n",
    "\n",
    "\n",
    "def validate_and_clean_cache(df, spectrogram_col=\"Spectrogram_Path\"):\n",
    "    bad_indices = []\n",
    "    for idx, row in df.iterrows():\n",
    "        path = Path(row.get(spectrogram_col, \"\"))\n",
    "        if not path.exists():\n",
    "            bad_indices.append(idx)\n",
    "            continue\n",
    "        try:\n",
    "            with open(path, \"rb\") as f:\n",
    "                _ = torch.load(f, map_location=\"cuda\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Invalid spectrogram at {path}: {e}\")\n",
    "            try:\n",
    "                path.unlink()\n",
    "                print(f\"üóëÔ∏è Deleted corrupt file: {path}\")\n",
    "            except Exception as delete_err:\n",
    "                print(f\"‚ö†Ô∏è Could not delete file: {delete_err}\")\n",
    "            bad_indices.append(idx)\n",
    "    return bad_indices\n",
    "\n",
    "# Run validation/cleanup pipeline\n",
    "bad_indices = validate_and_clean_cache(music_df)"
   ],
   "id": "1c8d947dcc87ad36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "spectrogram_cache_dir = Path(\"spectrogram_cache\")\n",
    "\n",
    "for pkl_path in spectrogram_cache_dir.glob(\"*.pkl\"):\n",
    "    try:\n",
    "        # Try loading using torch.load\n",
    "        _ = torch.load(pkl_path, map_location=\"cuda\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Deleting corrupted spectrogram: {pkl_path}\")\n",
    "        pkl_path.unlink()"
   ],
   "id": "16a6b28cf4ed3174",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bad_indices = scan_and_fix_spectrogram_cache(music_df)\n",
    "if bad_indices:\n",
    "    regenerate_spectrograms(music_df, bad_indices)\n",
    "    music_df.to_pickle(\"music_df_fixed.pkl\")"
   ],
   "id": "fb465ce126a9a6ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "music_df.to_pickle(\"music_data.pkl\")",
   "id": "f3b999bbd78d11af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Add a new column 'Seq_Length' representing the length of MIDI token sequences\n",
    "music_df[\"Seq_Length\"] = music_df[\"Encoded_MIDI_Tokens\"].apply(lambda x: len(x) if isinstance(x, list) else 0)"
   ],
   "id": "133d5ed0340abbc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bb2e2a8275ee3542",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "music_df.to_pickle(\"music_data_with_lengths.pkl\")",
   "id": "124a2fb2ed2007f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"Pads MIDI sequences and stacks spectrograms for batching.\"\"\"\n",
    "    spectrograms, midi_tokens = zip(*batch)\n",
    "\n",
    "    # üîπ Ensure MIDI tokens are lists (for padding compatibility)\n",
    "    midi_tokens = [torch.tensor(seq, dtype=torch.long) if isinstance(seq, (list, np.ndarray)) else torch.tensor([0]) for\n",
    "                   seq in midi_tokens]\n",
    "\n",
    "    # üîπ Pad MIDI sequences to the max length in batch\n",
    "    midi_tokens_padded = pad_sequence(midi_tokens, batch_first=True, padding_value=0)\n",
    "\n",
    "    # üîπ Ensure spectrograms have the same shape before stacking\n",
    "    try:\n",
    "        spectrograms = torch.stack(spectrograms)  # Shape: (B, 6, Freq, Time)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error stacking spectrograms: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    return spectrograms, midi_tokens_padded\n"
   ],
   "id": "e9fd178d74bab730",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MaestroDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        # Drop rows with missing spectrogram paths or encoded MIDI tokens\n",
    "        self.df = df.dropna(subset=[\"Spectrogram_Path\", \"Encoded_MIDI_Tokens\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of valid rows in the DataFrame\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve the row at the given index\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Load the spectrogram from the given path\n",
    "        spectrogram_path = row[\"Spectrogram_Path\"]\n",
    "        if not spectrogram_path or not os.path.exists(spectrogram_path):\n",
    "            print(f\"Warning: Missing spectrogram file {spectrogram_path}\")\n",
    "            return None  # Handle missing spectrogram files\n",
    "\n",
    "        try:\n",
    "            with open(spectrogram_path, \"rb\") as f:\n",
    "                spectrogram = pickle.load(f)\n",
    "            # Ensure the spectrogram is a torch tensor\n",
    "            if not isinstance(spectrogram, torch.Tensor):\n",
    "                spectrogram = torch.tensor(spectrogram, dtype=torch.float32)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading spectrogram {spectrogram_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "        # Load and validate MIDI tokens\n",
    "        midi_tokens = row[\"Encoded_MIDI_Tokens\"]\n",
    "        if isinstance(midi_tokens, list):\n",
    "            midi_tokens = torch.tensor(midi_tokens, dtype=torch.long)\n",
    "        else:\n",
    "            print(f\"Warning: Invalid MIDI tokens at index {idx}\")\n",
    "            # Default to an empty token if invalid\n",
    "            midi_tokens = torch.tensor([0], dtype=torch.long)\n",
    "\n",
    "        return spectrogram, midi_tokens"
   ],
   "id": "17680dc6504b6e2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the DataFrame for later use in training\n",
    "music_df.to_pickle(\"music_df.pkl\")\n",
    "print(\"‚úÖ DataFrame saved as music_df.pkl\")\n"
   ],
   "id": "be1c5ccbd55d5cc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Bin sequence lengths into quantiles and assign them to a new column\n",
    "music_df[\"Length_Bin\"] = pd.qcut(music_df[\"Seq_Length\"], q=10, duplicates=\"drop\")\n",
    "\n",
    "# Split the dataset into training (70%), validation (10%) and testing (20%) sets, stratified by sequence length bins\n",
    "train_df, temp_df = train_test_split(\n",
    "    music_df,\n",
    "    test_size=0.3,  # 30% goes to val + test\n",
    "    stratify=music_df[\"Length_Bin\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=2/3,  # 2/3 of temp = 20% of original\n",
    "    stratify=temp_df[\"Length_Bin\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "# Save the training and testing datasets to separate pickle files\n",
    "train_df.to_pickle(\"train_split.pkl\")\n",
    "val_df.to_pickle(\"val_split.pkl\")\n",
    "test_df.to_pickle(\"test_split.pkl\")"
   ],
   "id": "7cda12d0d8994308",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Open a file to save dataset splitting information\n",
    "with open(\"data_split_info.txt\", \"w\") as f:\n",
    "    # Write the number of training samples to the file\n",
    "    f.write(f\"Train samples: {len(train_df)}\\n\")\n",
    "    # Write the number of testing samples to the file\n",
    "    f.write(f\"Test samples: {len(test_df)}\\n\")\n",
    "    # Write the distribution of sequence length bins to the file\n",
    "    f.write(f\"Bins:\\n{music_df['Length_Bin'].value_counts().sort_index()}\")"
   ],
   "id": "5bc17cb25593fd2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the training dataset from the pickle file\n",
    "df = pd.read_pickle(\"train_split.pkl\")\n",
    "\n",
    "# Filter rows where 'Spectrogram_Path' or 'Encoded_MIDI_Tokens' are missing\n",
    "bad_rows = df[df[\"Spectrogram_Path\"].isnull() | df[\"Encoded_MIDI_Tokens\"].isnull()]\n",
    "\n",
    "# Display the count of problematic rows in the training set\n",
    "print(f\"‚ö†Ô∏è Bad samples in training set: {len(bad_rows)}\")\n",
    "\n",
    "# Print details of the problematic rows including MIDI and WAV paths\n",
    "print(bad_rows[[\".midi\", \".wav\", \"Spectrogram_Path\"]])"
   ],
   "id": "3c919c7e23c43b8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df.dropna(subset=[\"Spectrogram_Path\", \"Encoded_MIDI_Tokens\"])",
   "id": "6279d69beb35c1b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to fetch the spectrogram length from a file\n",
    "def get_spec_length(path):\n",
    "    try:\n",
    "        # Open the file in binary read mode and load its contents\n",
    "        with open(path, \"rb\") as f:\n",
    "            return pickle.load(f).shape[-1]  # Return the last dimension of the spectrogram\n",
    "    except:\n",
    "        # Return 0 if an error occurs (e.g., file not found or corrupted)\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Add a new column 'Spec_Length' by applying the function to each Spectrogram_Path\n",
    "df[\"Spec_Length\"] = df[\"Spectrogram_Path\"].apply(get_spec_length)\n",
    "\n",
    "# Save the updated DataFrame with the new column to a pickle file\n",
    "df.to_pickle(\"train_split_with_spec_len.pkl\")"
   ],
   "id": "a8f641021755193a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Delete DataFrames from memory to free up resources\n",
    "del music_df, train_df, test_df, val_df, bad_rows\n",
    "\n",
    "# Manually trigger garbage collection to clean up unused objects\n",
    "gc.collect()\n",
    "\n",
    "# Clear CUDA memory to avoid memory leaks or overflow on GPU\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "3b1516e8677d42d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "music_df = pd.read_pickle(\"music_df.pkl\")\n",
    "velocities = []\n",
    "durations = []\n",
    "time_gaps = []\n",
    "\n",
    "for tokens in music_df[\"MIDI_Tokens\"]:\n",
    "    if tokens:\n",
    "        for pitch, velocity, duration, gap in tokens:\n",
    "            velocities.append(velocity)\n",
    "            durations.append(duration)\n",
    "            time_gaps.append(gap)\n",
    "\n",
    "plt.hist(velocities, bins=128)\n",
    "plt.title(\"Velocity Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(durations, bins=100)\n",
    "plt.title(\"Duration Distribution (seconds)\")\n",
    "plt.xscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(time_gaps, bins=100)\n",
    "plt.title(\"Time Since Last Note (seconds)\")\n",
    "plt.xscale(\"log\")\n",
    "plt.show()"
   ],
   "id": "ca2780168aff8af7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Quantizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        velocity_bins=32,\n",
    "        duration_bins=64,\n",
    "        duration_range=(0.01, 10.0),\n",
    "        time_bins=32,\n",
    "        time_range=(0.01, 8.0),\n",
    "    ):\n",
    "        self.velocity_bins = velocity_bins\n",
    "        self.duration_bins = duration_bins\n",
    "        self.time_bins = time_bins\n",
    "\n",
    "        # Velocity edges are implicit (fixed-width)\n",
    "        self.velocity_bin_size = 128 / velocity_bins\n",
    "\n",
    "        # Log-space bins for duration and time\n",
    "        self.duration_edges = np.logspace(np.log10(duration_range[0]), np.log10(duration_range[1]), num=duration_bins + 1)\n",
    "        self.time_edges = np.logspace(np.log10(time_range[0]), np.log10(time_range[1]), num=time_bins + 1)\n",
    "\n",
    "    def velocity_bin(self, velocity):\n",
    "        \"\"\"Quantize velocity [0‚Äì127] into bins.\"\"\"\n",
    "        bin_idx = int(velocity // self.velocity_bin_size)\n",
    "        return min(bin_idx, self.velocity_bins - 1)\n",
    "\n",
    "    def duration_bin(self, duration_sec):\n",
    "        \"\"\"Quantize duration (in seconds) into log-spaced bins.\"\"\"\n",
    "        bin_idx = np.digitize(duration_sec, self.duration_edges) - 1\n",
    "        return int(np.clip(bin_idx, 0, self.duration_bins - 1))\n",
    "\n",
    "    def time_bin(self, time_sec):\n",
    "        \"\"\"Quantize time since the last note (in seconds) into log-spaced bins.\"\"\"\n",
    "        bin_idx = np.digitize(time_sec, self.time_edges) - 1\n",
    "        return int(np.clip(bin_idx, 0, self.time_bins - 1))\n",
    "\n",
    "    def inverse_velocity(self, bin_idx):\n",
    "        \"\"\"Approximate original velocity from bin.\"\"\"\n",
    "        return int((bin_idx + 0.5) * self.velocity_bin_size)\n",
    "\n",
    "    def inverse_duration(self, bin_idx):\n",
    "        \"\"\"Approximate original duration (seconds) from bin.\"\"\"\n",
    "        bin_idx = np.clip(bin_idx, 0, self.duration_bins - 1)\n",
    "        return float((self.duration_edges[bin_idx] + self.duration_edges[bin_idx + 1]) / 2)\n",
    "\n",
    "    def inverse_time(self, bin_idx):\n",
    "        \"\"\"Approximate original time gap (seconds) from bin.\"\"\"\n",
    "        bin_idx = np.clip(bin_idx, 0, self.time_bins - 1)\n",
    "        return float((self.time_edges[bin_idx] + self.time_edges[bin_idx + 1]) / 2)"
   ],
   "id": "99a81630548b7650",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "music_ai",
   "language": "python",
   "display_name": "Python 3.11 (Music_AI)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
